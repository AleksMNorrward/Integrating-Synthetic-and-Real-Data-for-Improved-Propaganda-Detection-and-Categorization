{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Propaganda Classifier Agent**"
      ],
      "metadata": {
        "id": "-jBqT7c-G8ZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Dataset Downloading**"
      ],
      "metadata": {
        "id": "I9LFYC3xSmKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzBucUB59TOS",
        "outputId": "cd8712aa-85dd-4f1f-c262-3511e540490d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "id": "3D1Tx-Sl9XMc",
        "outputId": "136eedfa-9519-434e-aefa-05069e5b29b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-31c210db-994a-4b35-af0e-7bd4404f7985\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-31c210db-994a-4b35-af0e-7bd4404f7985\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"aleksrusso2001\",\"key\":\"3f84f65ce31e7950b99ea4196c4ec133\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Grcx-AW9ho0",
        "outputId": "29ee3806-d6f9-4c7a-9b65-2ce60d3a6ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 70 Apr 29 14:38 kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "1L6uwsao9pVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle #Create the directory\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "0Jd_VkmO9qTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "O8kRmLl-9zVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d bohdanmynzar/twitter-propaganda-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O91AZOLz98XU",
        "outputId": "a75b5173-f860-4a0e-c4c1-2c9352e58588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading twitter-propaganda-classification.zip to /content\n",
            "\r  0% 0.00/2.24M [00:00<?, ?B/s]\n",
            "\r100% 2.24M/2.24M [00:00<00:00, 108MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip twitter-propaganda-classification.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa8H_8Uh-BF7",
        "outputId": "05556809-c169-4851-f8bb-0a7373078be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  twitter-propaganda-classification.zip\n",
            "  inflating: twitter_dataset.csv     \n",
            "  inflating: twitter_dataset_translated_ukrainian.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/twitter_dataset.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "U7sgUs5M-EIW",
        "outputId": "83fee514-7fee-4632-a55c-6a25a66aae5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                   id                 created_at  \\\n",
              "0        1749  1514553915580329988  2022-04-14 10:39:27+00:00   \n",
              "1        2409  1510803460320632839  2022-04-04 02:16:28+00:00   \n",
              "2        2463  1475560113536741379  2021-12-27 20:12:00+00:00   \n",
              "3         116  1527722359314075649  2022-05-20 18:46:08+00:00   \n",
              "4        2742  1517110124325879808  2022-04-21 11:56:54+00:00   \n",
              "\n",
              "                                                text  is_propaganda  \n",
              "0  Woman who held up poster of Marine Le Pen and ...          False  \n",
              "1  ⚡️Zelensky: Around 150,000 people trapped in M...          False  \n",
              "2  RT @natomission_ru: 🇷🇺#Russia Deputy FM Sergey...           True  \n",
              "3  #Azovstal fully liberated – Russian military\\n...           True  \n",
              "4  RT @BloombergUK: \"He was almost foaming at the...          False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-468e0ba7-5b4f-4a2d-bf03-6f1a69c189ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>is_propaganda</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1749</td>\n",
              "      <td>1514553915580329988</td>\n",
              "      <td>2022-04-14 10:39:27+00:00</td>\n",
              "      <td>Woman who held up poster of Marine Le Pen and ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2409</td>\n",
              "      <td>1510803460320632839</td>\n",
              "      <td>2022-04-04 02:16:28+00:00</td>\n",
              "      <td>⚡️Zelensky: Around 150,000 people trapped in M...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2463</td>\n",
              "      <td>1475560113536741379</td>\n",
              "      <td>2021-12-27 20:12:00+00:00</td>\n",
              "      <td>RT @natomission_ru: 🇷🇺#Russia Deputy FM Sergey...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>116</td>\n",
              "      <td>1527722359314075649</td>\n",
              "      <td>2022-05-20 18:46:08+00:00</td>\n",
              "      <td>#Azovstal fully liberated – Russian military\\n...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2742</td>\n",
              "      <td>1517110124325879808</td>\n",
              "      <td>2022-04-21 11:56:54+00:00</td>\n",
              "      <td>RT @BloombergUK: \"He was almost foaming at the...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-468e0ba7-5b4f-4a2d-bf03-6f1a69c189ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-468e0ba7-5b4f-4a2d-bf03-6f1a69c189ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-468e0ba7-5b4f-4a2d-bf03-6f1a69c189ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-533ca4d6-f187-45f7-80a2-16281169cc5d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-533ca4d6-f187-45f7-80a2-16281169cc5d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-533ca4d6-f187-45f7-80a2-16281169cc5d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 12990,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 938,\n        \"min\": 0,\n        \"max\": 3248,\n        \"num_unique_values\": 3249,\n        \"samples\": [\n          1257,\n          1249,\n          2506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15369855971993718,\n        \"min\": 1459969492910546946,\n        \"max\": 1528501269903687680,\n        \"num_unique_values\": 12990,\n        \"samples\": [\n          1514294846080659456,\n          1476065442796081155,\n          1516431252336918533\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 12824,\n        \"samples\": [\n          \"2022-04-28 21:56:53+00:00\",\n          \"2022-04-03 21:26:11+00:00\",\n          \"2022-02-09 14:21:19+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12979,\n        \"samples\": [\n          \"RT @RusEmbUSA: \\ud83d\\udd3b\\r\\n\\ud83d\\uddd3\\ufe0fOn February\\ud83d\\udd1fmembers of the Russian foreign service celebrate their professional holiday - #DiplomatsDay \\r\\nPlease enjoy @R\\u2026\",\n          \"\\u26a1\\ufe0fMan opens fire in kindergarten in Russia's Ulyanovsk Region - reports https://t.co/5r78LLzXV3\",\n          \"Shark infested waters in Florida prompt sheriff warning https://t.co/AKCDot59QT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_propaganda\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.drop(columns=['Unnamed: 0', 'id', 'created_at'])"
      ],
      "metadata": {
        "id": "TZ-Ghx5O-KnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "Vbee0u9xTAHZ",
        "outputId": "dcf84f35-eb57-461e-ba28-eac9cd6b3cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  is_propaganda\n",
              "0      Woman who held up poster of Marine Le Pen and ...          False\n",
              "1      ⚡️Zelensky: Around 150,000 people trapped in M...          False\n",
              "2      RT @natomission_ru: 🇷🇺#Russia Deputy FM Sergey...           True\n",
              "3      #Azovstal fully liberated – Russian military\\n...           True\n",
              "4      RT @BloombergUK: \"He was almost foaming at the...          False\n",
              "...                                                  ...            ...\n",
              "12985  \"There is real genocide - what you have seen h...          False\n",
              "12986  ⚡️ Finland imported 70% less crude oil from Ru...          False\n",
              "12987  Can Congress legalise abortion if Supreme Cour...          False\n",
              "12988  RT @mod_russia: In total 2,241 Russian and for...           True\n",
              "12989  Karine Jean-Pierre will replace White House Pr...          False\n",
              "\n",
              "[12990 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c96d14b-d1de-4d5a-97d4-26afabf13af7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>is_propaganda</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Woman who held up poster of Marine Le Pen and ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>⚡️Zelensky: Around 150,000 people trapped in M...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @natomission_ru: 🇷🇺#Russia Deputy FM Sergey...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#Azovstal fully liberated – Russian military\\n...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @BloombergUK: \"He was almost foaming at the...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12985</th>\n",
              "      <td>\"There is real genocide - what you have seen h...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12986</th>\n",
              "      <td>⚡️ Finland imported 70% less crude oil from Ru...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12987</th>\n",
              "      <td>Can Congress legalise abortion if Supreme Cour...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12988</th>\n",
              "      <td>RT @mod_russia: In total 2,241 Russian and for...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12989</th>\n",
              "      <td>Karine Jean-Pierre will replace White House Pr...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12990 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c96d14b-d1de-4d5a-97d4-26afabf13af7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c96d14b-d1de-4d5a-97d4-26afabf13af7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c96d14b-d1de-4d5a-97d4-26afabf13af7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74f883e5-17a6-46a3-9088-75151067dd35\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74f883e5-17a6-46a3-9088-75151067dd35')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74f883e5-17a6-46a3-9088-75151067dd35 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 12990,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12979,\n        \"samples\": [\n          \"RT @RusEmbUSA: \\ud83d\\udd3b\\r\\n\\ud83d\\uddd3\\ufe0fOn February\\ud83d\\udd1fmembers of the Russian foreign service celebrate their professional holiday - #DiplomatsDay \\r\\nPlease enjoy @R\\u2026\",\n          \"\\u26a1\\ufe0fMan opens fire in kindergarten in Russia's Ulyanovsk Region - reports https://t.co/5r78LLzXV3\",\n          \"Shark infested waters in Florida prompt sheriff warning https://t.co/AKCDot59QT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_propaganda\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Agent 29.04.24**"
      ],
      "metadata": {
        "id": "8fOZAsfcTMkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet mesa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMMNhrlUTRYt",
        "outputId": "b01a1a63-83b8-44ab-cb31-bb65bea85b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mesa\n",
        "\n",
        "# Data visualization tools.\n",
        "import seaborn as sns\n",
        "\n",
        "# Has multi-dimensional arrays and matrices. Has a large collection of\n",
        "# mathematical functions to operate on these arrays.\n",
        "import numpy as np\n",
        "\n",
        "# Data manipulation and analysis.\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "BuBd6S8XTaAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EXGb-qhtaZMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mesa import Agent, Model\n",
        "from mesa.time import RandomActivation\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BdiAgent(Agent):\n",
        "    \"\"\"An agent with beliefs, desires, and intentions.\"\"\"\n",
        "    def __init__(self, unique_id, model, text):\n",
        "        super().__init__(unique_id, model)\n",
        "        self.text = text\n",
        "        self.beliefs = {}\n",
        "        self.desires = []\n",
        "        self.intentions = []\n",
        "\n",
        "    def perceive(self):\n",
        "        \"\"\"Update beliefs based on text.\"\"\"\n",
        "        self.beliefs['text'] = self.text\n",
        "\n",
        "    def select_desires(self):\n",
        "        \"\"\"Select desires based on beliefs.\"\"\"\n",
        "        # No need to select desires in this case\n",
        "\n",
        "    def form_intentions(self):\n",
        "        \"\"\"Form intentions based on beliefs.\"\"\"\n",
        "        # No need to form intentions in this case\n",
        "\n",
        "    def act(self):\n",
        "        \"\"\"Execute actions based on intentions.\"\"\"\n",
        "        # No need to act in this case\n",
        "\n",
        "class BdiModel(Model):\n",
        "    \"\"\"A model containing BDI agents.\"\"\"\n",
        "    def __init__(self, N, features, labels, maxlen=200, vocab_size=10000):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.maxlen = maxlen\n",
        "        self.vocab_size = vocab_size\n",
        "        self.schedule = RandomActivation(self)\n",
        "        self.initialize_classifier()\n",
        "\n",
        "    def initialize_classifier(self):\n",
        "        \"\"\"Initialize and train the classifier.\"\"\"\n",
        "        tokenizer = Tokenizer(num_words=self.vocab_size)\n",
        "        tokenizer.fit_on_texts(self.features)\n",
        "        sequences = tokenizer.texts_to_sequences(self.features)\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=self.maxlen)\n",
        "        x_train, x_val, y_train, y_val = train_test_split(padded_sequences, self.labels, test_size=0.2, random_state=42)\n",
        "        x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, random_state=42)\n",
        "\n",
        "        embed_dim = 32\n",
        "        num_heads = 2\n",
        "        ff_dim = 32\n",
        "\n",
        "        inputs = layers.Input(shape=(self.maxlen,))\n",
        "        embedding_layer = TokenAndPositionEmbedding(self.maxlen, self.vocab_size, embed_dim)\n",
        "        x = embedding_layer(inputs)\n",
        "        transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "        x = transformer_block(x)\n",
        "        x = layers.GlobalAveragePooling1D()(x)\n",
        "        x = layers.Dropout(0.1)(x)\n",
        "        x = layers.Dense(60, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(0.1)(x)\n",
        "        x = layers.Dense(40, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(0.1)(x)\n",
        "        x = layers.Dense(20, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(0.1)(x)\n",
        "        outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "        self.classifier_model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "        self.classifier_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "        history = self.classifier_model.fit(x_train, y_train, batch_size=32, epochs=20, validation_data=(x_val, y_val))\n",
        "        self.classifier_model.summary()\n",
        "\n",
        "        test_loss, test_accuracy = self.classifier_model.evaluate(x_test, y_test)\n",
        "        print(\"Test Loss:\", test_loss)\n",
        "        print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('Classifier Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('Classifier Model Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"Advance the model by one step.\"\"\"\n",
        "        for agent in self.schedule.agents:\n",
        "            agent.perceive()\n",
        "            # No need to select desires, form intentions, or act in this case\n",
        "\n",
        "# Example environment\n",
        "features = df['text']\n",
        "labels = df['is_propaganda']\n",
        "\n",
        "# Create a BDI model with 3 agents\n",
        "model = BdiModel(3, features, labels)\n",
        "\n",
        "# Run the model for one step\n",
        "model.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bap-kCgsaT4M",
        "outputId": "cb7b140a-98ac-4ff6-8724-1caa8120f34c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "325/325 [==============================] - 44s 118ms/step - loss: 0.6969 - accuracy: 0.5069 - val_loss: 0.6697 - val_accuracy: 0.7768\n",
            "Epoch 2/20\n",
            "325/325 [==============================] - 34s 103ms/step - loss: 0.4113 - accuracy: 0.7982 - val_loss: 0.2758 - val_accuracy: 0.8753\n",
            "Epoch 3/20\n",
            "325/325 [==============================] - 36s 109ms/step - loss: 0.1835 - accuracy: 0.9297 - val_loss: 0.3183 - val_accuracy: 0.8514\n",
            "Epoch 4/20\n",
            "325/325 [==============================] - 33s 103ms/step - loss: 0.1109 - accuracy: 0.9612 - val_loss: 0.3873 - val_accuracy: 0.8753\n",
            "Epoch 5/20\n",
            "325/325 [==============================] - 32s 97ms/step - loss: 0.0552 - accuracy: 0.9824 - val_loss: 0.5599 - val_accuracy: 0.8799\n",
            "Epoch 6/20\n",
            "325/325 [==============================] - 32s 99ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 0.5317 - val_accuracy: 0.8799\n",
            "Epoch 7/20\n",
            "325/325 [==============================] - 33s 102ms/step - loss: 0.0213 - accuracy: 0.9946 - val_loss: 0.5378 - val_accuracy: 0.8768\n",
            "Epoch 8/20\n",
            "325/325 [==============================] - 33s 102ms/step - loss: 0.0171 - accuracy: 0.9961 - val_loss: 0.8952 - val_accuracy: 0.8707\n",
            "Epoch 9/20\n",
            "325/325 [==============================] - 33s 100ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.8716 - val_accuracy: 0.8707\n",
            "Epoch 10/20\n",
            "325/325 [==============================] - 33s 103ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 1.0726 - val_accuracy: 0.8714\n",
            "Epoch 11/20\n",
            "325/325 [==============================] - 32s 100ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 1.0252 - val_accuracy: 0.8645\n",
            "Epoch 12/20\n",
            "325/325 [==============================] - 31s 95ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 1.3772 - val_accuracy: 0.8607\n",
            "Epoch 13/20\n",
            "325/325 [==============================] - 34s 105ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.9998 - val_accuracy: 0.8699\n",
            "Epoch 14/20\n",
            "325/325 [==============================] - 29s 90ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.8795 - val_accuracy: 0.8622\n",
            "Epoch 15/20\n",
            "325/325 [==============================] - 29s 90ms/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.9628 - val_accuracy: 0.8714\n",
            "Epoch 16/20\n",
            "325/325 [==============================] - 30s 94ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.8381 - val_accuracy: 0.8761\n",
            "Epoch 17/20\n",
            "325/325 [==============================] - 29s 90ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 1.1562 - val_accuracy: 0.8745\n",
            "Epoch 18/20\n",
            "325/325 [==============================] - 29s 90ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 1.2489 - val_accuracy: 0.8730\n",
            "Epoch 19/20\n",
            "325/325 [==============================] - 30s 93ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 1.4045 - val_accuracy: 0.8684\n",
            "Epoch 20/20\n",
            "325/325 [==============================] - 29s 90ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 1.1436 - val_accuracy: 0.8676\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 200)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddi  (None, 200, 32)           326400    \n",
            " ng_3 (TokenAndPositionEmbe                                      \n",
            " dding)                                                          \n",
            "                                                                 \n",
            " transformer_block (Transfo  (None, 200, 32)           10656     \n",
            " rmerBlock)                                                      \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 32)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 60)                1980      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 60)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 40)                2440      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 40)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                820       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 342338 (1.31 MB)\n",
            "Trainable params: 342338 (1.31 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "41/41 [==============================] - 1s 33ms/step - loss: 1.0100 - accuracy: 0.8799\n",
            "Test Loss: 1.0100014209747314\n",
            "Test Accuracy: 0.8799076080322266\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Agent 28.04.24**"
      ],
      "metadata": {
        "id": "W7NUYFwJTEMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassifierAgent(Agent):\n",
        "    def __init__(self, unique_id, model, data_frame, text_column, label_column):\n",
        "        super().__init__(unique_id, model)\n",
        "        self.data_frame = data_frame\n",
        "        self.text_column = text_column\n",
        "        self.label_column = label_column\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-5)\n",
        "\n",
        "    def step(self):\n",
        "        # Preprocess the data\n",
        "        if self.text_column not in self.data_frame.columns:\n",
        "            raise KeyError(f\"Text column '{self.text_column}' not found in the dataset.\")\n",
        "        if self.label_column not in self.data_frame.columns:\n",
        "            raise KeyError(f\"Label column '{self.label_column}' not found in the dataset.\")\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            self.data_frame[self.text_column],\n",
        "            self.data_frame[self.label_column],\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "        train_inputs = self.tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        train_labels = torch.tensor(y_train.tolist())\n",
        "        test_inputs = self.tokenizer(X_test.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        test_labels = torch.tensor(y_test.tolist())\n",
        "\n",
        "        train_data = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
        "        test_data = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\n",
        "\n",
        "        train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "        test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "\n",
        "        # Training loop\n",
        "        self.model.train()\n",
        "        for batch in train_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        # Evaluation\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                input_ids, attention_mask, labels = batch\n",
        "                input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                predictions = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
        "                correct_predictions += torch.sum(predictions == labels).item()\n",
        "                total_predictions += len(labels)\n",
        "                loss = F.cross_entropy(logits, labels)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        accuracy = correct_predictions / total_predictions\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Accuracy: {accuracy}, Loss: {avg_loss}\")\n",
        "\n",
        "class TransformerClassifierModel(Model):\n",
        "    \"\"\"A model with some number of agents.\"\"\"\n",
        "    def __init__(self, N, data_frame, text_column, label_column):\n",
        "        super().__init__()\n",
        "        self.num_agents = N\n",
        "        self.schedule = RandomActivation(self)\n",
        "        self.data_frame = data_frame\n",
        "        self.text_column = text_column\n",
        "        self.label_column = label_column\n",
        "        if label_column not in data_frame.columns:\n",
        "            raise KeyError(f\"Label column '{label_column}' not found in the dataset.\")\n",
        "        num_labels = len(data_frame[label_column].unique())\n",
        "        self.model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "        self.agents_ = defaultdict(dict)  # Initialize agents_ attribute\n",
        "        for i in range(self.num_agents):\n",
        "            agent = TransformerClassifierAgent(i, self.model, data_frame, text_column, label_column)\n",
        "            self.schedule.add(agent)\n",
        "            self.agents_[type(agent)][agent] = None\n",
        "\n",
        "    def step(self):\n",
        "        self.schedule.step()\n",
        "\n",
        "# Example usage\n",
        "#data = pd.read_csv(\"your_dataset.csv\")  # Load your dataset\n",
        "model = TransformerClassifierModel(1, data, \"text\", \"is_propaganda\")\n",
        "model.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "VAwdJ1HBJg4P",
        "outputId": "9e6f41c1-0e45-400d-f8c8-e06ab7b5c352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-35-59da218b4de6>:3: FutureWarning: The Mesa Model class was not initialized. In the future, you need to explicitly initialize the Model by calling super().__init__() on initialization.\n",
            "  super().__init__(unique_id, model)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Target size (torch.Size([16])) must be the same as input size (torch.Size([16, 2]))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-59da218b4de6>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m#data = pd.read_csv(\"your_dataset.csv\")  # Load your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerClassifierModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_propaganda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-59da218b4de6>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/time.py\u001b[0m in \u001b[0;36m_wrapped_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"\"\"Wrapper for the step method to include time and step updating.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/time.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \"\"\"\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_each\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/time.py\u001b[0m in \u001b[0;36mdo_each\u001b[0;34m(self, method, shuffle)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/agent.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(self, method_name, return_results, *args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# we iterate over the actual weakref keys and check if weakref is alive before calling the method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         res = [\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0magentref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyrefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# we iterate over the actual weakref keys and check if weakref is alive before calling the method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         res = [\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0magentref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyrefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0magentref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-59da218b4de6>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    726\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3197\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Target size ({target.size()}) must be the same as input size ({input.size()})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([16])) must be the same as input size (torch.Size([16, 2]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from mesa import Agent, Model\n",
        "from mesa.time import RandomActivation\n",
        "from collections import defaultdict\n",
        "\n",
        "class TransformerClassifierAgent(Agent):\n",
        "    def __init__(self, unique_id, model, data_frame, text_column, label_column):\n",
        "        super().__init__(unique_id, model)\n",
        "        self.data_frame = data_frame\n",
        "        self.text_column = text_column\n",
        "        self.label_column = label_column\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-5)\n",
        "\n",
        "    def step(self):\n",
        "        # Preprocess the data\n",
        "        if self.text_column not in self.data_frame.columns:\n",
        "            raise KeyError(f\"Text column '{self.text_column}' not found in the dataset.\")\n",
        "        if self.label_column not in self.data_frame.columns:\n",
        "            raise KeyError(f\"Label column '{self.label_column}' not found in the dataset.\")\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            self.data_frame[self.text_column],\n",
        "            self.data_frame[self.label_column],\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "        train_inputs = self.tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        train_labels = torch.tensor(y_train.tolist())\n",
        "        test_inputs = self.tokenizer(X_test.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        test_labels = torch.tensor(y_test.tolist())\n",
        "\n",
        "        train_data = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
        "        test_data = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\n",
        "\n",
        "        train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "        test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "\n",
        "        # Training loop\n",
        "        self.model.train()\n",
        "        for batch in train_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        # Evaluation\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                input_ids, attention_mask, labels = batch\n",
        "                input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                total_loss += loss.item()\n",
        "                logits = outputs.logits\n",
        "                predictions = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
        "                correct_predictions += torch.sum(predictions == labels).item()\n",
        "                total_predictions += len(labels)\n",
        "\n",
        "        accuracy = correct_predictions / total_predictions\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Accuracy: {accuracy}, Loss: {avg_loss}\")\n",
        "\n",
        "class TransformerClassifierModel(Model):\n",
        "    \"\"\"A model with some number of agents.\"\"\"\n",
        "    def __init__(self, N, data_frame, text_column, label_column):\n",
        "        super().__init__()\n",
        "        self.num_agents = N\n",
        "        self.schedule = RandomActivation(self)\n",
        "        self.data_frame = data_frame\n",
        "        self.text_column = text_column\n",
        "        self.label_column = label_column\n",
        "        if label_column not in data_frame.columns:\n",
        "            raise KeyError(f\"Label column '{label_column}' not found in the dataset.\")\n",
        "        num_labels = len(data[label_column].unique())\n",
        "        self.model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "        self.model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=data_frame[label_column].nunique())\n",
        "        self.agents_ = defaultdict(dict)  # Initialize agents_ attribute\n",
        "        for i in range(self.num_agents):\n",
        "            agent = TransformerClassifierAgent(i, self.model, data_frame, text_column, label_column)\n",
        "            self.schedule.add(agent)\n",
        "            self.agents_[type(agent)][agent] = None\n",
        "\n",
        "    def step(self):\n",
        "        self.schedule.step()\n",
        "\n",
        "# Example usage\n",
        "#data = pd.read_csv(\"your_dataset.csv\")  # Load your dataset\n",
        "model = TransformerClassifierModel(1, data, \"text\", \"is_propaganda\")\n",
        "model.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "Rzc-lCwsH7Yz",
        "outputId": "17038dcb-799b-486b-d25e-9d59aede2913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-34-94ba12231902>:13: FutureWarning: The Mesa Model class was not initialized. In the future, you need to explicitly initialize the Model by calling super().__init__() on initialization.\n",
            "  super().__init__(unique_id, model)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Target size (torch.Size([16])) must be the same as input size (torch.Size([16, 2]))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-94ba12231902>\u001b[0m in \u001b[0;36m<cell line: 105>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#data = pd.read_csv(\"your_dataset.csv\")  # Load your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerClassifierModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_propaganda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-94ba12231902>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/time.py\u001b[0m in \u001b[0;36m_wrapped_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"\"\"Wrapper for the step method to include time and step updating.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/time.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \"\"\"\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_each\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/time.py\u001b[0m in \u001b[0;36mdo_each\u001b[0;34m(self, method, shuffle)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/agent.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(self, method_name, return_results, *args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# we iterate over the actual weakref keys and check if weakref is alive before calling the method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         res = [\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0magentref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyrefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# we iterate over the actual weakref keys and check if weakref is alive before calling the method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         res = [\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0magentref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyrefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0magentref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-94ba12231902>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    726\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3197\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Target size ({target.size()}) must be the same as input size ({input.size()})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([16])) must be the same as input size (torch.Size([16, 2]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from mesa import Agent, Model\n",
        "from mesa.time import RandomActivation\n",
        "\n",
        "class TransformerClassifierAgent(Agent):\n",
        "    def __init__(self, unique_id, model, data_frame, text_column, label_column):\n",
        "        super().__init__(unique_id, model)\n",
        "        self.data_frame = data_frame\n",
        "        self.text_column = text_column\n",
        "        self.label_column = label_column\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-5)\n",
        "\n",
        "    def step(self):\n",
        "        # Preprocess the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            self.data_frame[self.text_column],\n",
        "            self.data_frame[self.label_column],\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "        train_inputs = self.tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        train_labels = torch.tensor(y_train.tolist())\n",
        "        test_inputs = self.tokenizer(X_test.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        test_labels = torch.tensor(y_test.tolist())\n",
        "\n",
        "        train_data = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
        "        test_data = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\n",
        "\n",
        "        train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "        test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "\n",
        "        # Training loop\n",
        "        self.model.train()\n",
        "        for batch in train_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        # Evaluation\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                input_ids, attention_mask, labels = batch\n",
        "                input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                total_loss += loss.item()\n",
        "                logits = outputs.logits\n",
        "                predictions = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
        "                correct_predictions += torch.sum(predictions == labels).item()\n",
        "                total_predictions += len(labels)\n",
        "\n",
        "        accuracy = correct_predictions / total_predictions\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Accuracy: {accuracy}, Loss: {avg_loss}\")\n",
        "\n",
        "class TransformerClassifierModel(Model):\n",
        "    \"\"\"A model with some number of agents.\"\"\"\n",
        "    def __init__(self, N, data_frame, text_column, label_column):\n",
        "        super().__init__()\n",
        "        self.num_agents = N\n",
        "        self.schedule = RandomActivation(self)\n",
        "        self.data_frame = data_frame\n",
        "        self.text_column = text_column\n",
        "        self.label_column = label_column\n",
        "        self.model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=data_frame[label_column].nunique())\n",
        "        self.agents_ = defaultdict(dict)  # Initialize agents_ attribute\n",
        "        for i in range(self.num_agents):\n",
        "            agent = TransformerClassifierAgent(i, self.model, data_frame, text_column, label_column)\n",
        "            self.schedule.add(agent)\n",
        "            self.agents_[type(agent)][agent] = None\n",
        "\n",
        "    def step(self):\n",
        "        self.schedule.step()\n",
        "\n",
        "# Example usage\n",
        "#ata = pd.read_csv(\"your_dataset.csv\")  # Load your dataset\n",
        "model = TransformerClassifierModel(1, data, \"text\", \"label\")\n",
        "model.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "jQuF8p6aHP5b",
        "outputId": "dafe2515-96ed-4fdd-aeb3-78f2672c29ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'label'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-612fa3439a26>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m#ata = pd.read_csv(\"your_dataset.csv\")  # Load your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerClassifierModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-612fa3439a26>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, N, data_frame, text_column, label_column)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Initialize agents_ attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from mesa import Agent\n",
        "\n",
        "class TransformerClassifierAgent(Agent):\n",
        "    def __init__(self, unique_id, data_frame, text_column, label_column, model_name='bert-base-uncased'):\n",
        "        super().__init__(unique_id, None)\n",
        "        self.data_frame = data_frame\n",
        "        self.text_column = text_column\n",
        "        self.label_column = label_column\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = BertForSequenceClassification.from_pretrained(self.model_name, num_labels=self.data_frame[label_column].nunique()).to(self.device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-5)\n",
        "\n",
        "    def step(self):\n",
        "        # Preprocess the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            self.data_frame[self.text_column],\n",
        "            self.data_frame[self.label_column],\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "        train_inputs = self.tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        train_labels = torch.tensor(y_train.tolist())\n",
        "        test_inputs = self.tokenizer(X_test.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        test_labels = torch.tensor(y_test.tolist())\n",
        "\n",
        "        train_data = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
        "        test_data = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\n",
        "\n",
        "        train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "        test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "\n",
        "        # Training loop\n",
        "        self.model.train()\n",
        "        for batch in train_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        # Evaluation\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                input_ids, attention_mask, labels = batch\n",
        "                input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                total_loss += loss.item()\n",
        "                logits = outputs.logits\n",
        "                predictions = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
        "                correct_predictions += torch.sum(predictions == labels).item()\n",
        "                total_predictions += len(labels)\n",
        "\n",
        "        accuracy = correct_predictions / total_predictions\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Accuracy: {accuracy}, Loss: {avg_loss}\")\n",
        "\n",
        "# Example usage\n",
        "#data = pd.read_csv(\"your_dataset.csv\")  # Load your dataset\n",
        "agent = TransformerClassifierAgent(unique_id=1, data_frame=data, text_column=\"text\", label_column=\"label\")\n",
        "agent.step()\n"
      ],
      "metadata": {
        "id": "4fh43ENcFOci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "32d2ecd7-b737-4cfa-d778-97df4dcd7ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'agents_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, unique_id, model)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'agents_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-29c81047a248>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m#data = pd.read_csv(\"your_dataset.csv\")  # Load your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerClassifierAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-29c81047a248>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, unique_id, data_frame, text_column, label_column, model_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTransformerClassifierAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mesa/agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, unique_id, model)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# model super has not been called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magentset_experimental_warning_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'agents_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mesa import Agent, Model\n",
        "from mesa.time import RandomActivation\n",
        "from mesa.datacollection import DataCollector\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class TransformerAgent(Agent):\n",
        "    def __init__(self, unique_id, model, x_train, y_train, x_val, y_val, maxlen):\n",
        "        super().__init__(unique_id, model)\n",
        "        self.model = model\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_val = x_val\n",
        "        self.y_val = y_val\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def step(self):\n",
        "        embed_dim = 32\n",
        "        num_heads = 2\n",
        "        ff_dim = 32\n",
        "\n",
        "        transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "\n",
        "        inputs = keras.Input(shape=(self.maxlen,))\n",
        "        embedding_layer = TokenAndPositionEmbedding(self.maxlen, self.model.vocab_size, embed_dim)\n",
        "        x = embedding_layer(inputs)\n",
        "        x = transformer_block(x)\n",
        "        x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "        x = keras.layers.Dropout(0.1)(x)\n",
        "        x = keras.layers.Dense(60, activation=\"relu\")(x)\n",
        "        x = keras.layers.Dropout(0.1)(x)\n",
        "        x = keras.layers.Dense(40, activation=\"relu\")(x)\n",
        "        x = keras.layers.Dropout(0.1)(x)\n",
        "        x = keras.layers.Dense(20, activation=\"relu\")(x)\n",
        "        x = keras.layers.Dropout(0.1)(x)\n",
        "        outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "        history = model.fit(\n",
        "            self.x_train, self.y_train, batch_size=32, epochs=20, validation_data=(self.x_val, self.y_val), verbose=0\n",
        "        )\n",
        "\n",
        "        # Evaluate the model\n",
        "        val_pred = model.predict(self.x_val)\n",
        "        val_pred_classes = [1 if pred[1] > pred[0] else 0 for pred in val_pred]\n",
        "        val_accuracy = accuracy_score(self.y_val, val_pred_classes)\n",
        "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "class TransformerModel(Model):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.vocab_size = 10000\n",
        "        self.maxlen = 200\n",
        "\n",
        "        # Preprocess the data\n",
        "        features = self.df['text'].tolist()  # Convert DataFrame column to list\n",
        "        # Convert boolean labels to integer labels\n",
        "        labels = df['is_propaganda'].astype(int)\n",
        "\n",
        "        #labels = self.df['is_propaganda'].tolist()  # Convert DataFrame column to list\n",
        "\n",
        "        tokenizer = Tokenizer(num_words=self.vocab_size)\n",
        "        tokenizer.fit_on_texts(features)\n",
        "\n",
        "        sequences = tokenizer.texts_to_sequences(features)\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=self.maxlen)\n",
        "\n",
        "        x_train, x_val, y_train, y_val = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "        x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, random_state=42)\n",
        "\n",
        "        self.data = {\n",
        "            \"x_train\": x_train,\n",
        "            \"y_train\": y_train,\n",
        "            \"x_val\": x_val,\n",
        "            \"y_val\": y_val,\n",
        "            \"x_test\": x_test,\n",
        "            \"y_test\": y_test,\n",
        "        }\n",
        "\n",
        "        self.schedule = RandomActivation(self)\n",
        "        self.create_agents()\n",
        "\n",
        "    def create_agents(self):\n",
        "        for i in range(len(self.data['x_train'])):\n",
        "            agent = TransformerAgent(i, self, self.data['x_train'][i], self.data['y_train'][i],\n",
        "                                     self.data['x_val'], self.data['y_val'], self.maxlen)\n",
        "            self.schedule.add(agent)\n",
        "\n",
        "    def step(self):\n",
        "        self.schedule.step()\n",
        "\n",
        "# Load your DataFrame here\n",
        "# df = pd.read_csv(\"your_data.csv\")\n",
        "\n",
        "model = TransformerModel(df)\n",
        "for i in range(20):  # Run for 20 epochs\n",
        "    model.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "nQscLtw7_JJj",
        "outputId": "0d43ac57-bb07-4561-fe76-dc524ddd0277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-fafb086ff139>\u001b[0m in \u001b[0;36m<cell line: 101>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# df = pd.read_csv(\"your_data.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Run for 20 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-fafb086ff139>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-fafb086ff139>\u001b[0m in \u001b[0;36mcreate_agents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             agent = TransformerAgent(i, self, self.data['x_train'][i], self.data['y_train'][i],\n\u001b[0m\u001b[1;32m     92\u001b[0m                                      self.data['x_val'], self.data['y_val'], self.maxlen)\n\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from mesa import Agent, Model\n",
        "from mesa.time import RandomActivation\n",
        "\n",
        "class TransformerClassifierAgent(Agent):\n",
        "    def __init__(self, unique_id, data_frame, text_column, label_column, model_name='bert-base-uncased'):\n",
        "        super().__init__(unique_id, None)\n",
        "        self.data_frame = data_frame\n",
        "        self.text_column = text_column\n",
        "        self.label_column = label_column\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = BertForSequenceClassification.from_pretrained(self.model_name, num_labels=self.data_frame[label_column].nunique()).to(self.device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-5)\n",
        "\n",
        "    def step(self):\n",
        "        # Preprocess the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            self.data_frame[self.text_column],\n",
        "            self.data_frame[self.label_column],\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "        train_inputs = self.tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        train_labels = torch.tensor(y_train.tolist())\n",
        "        test_inputs = self.tokenizer(X_test.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        test_labels = torch.tensor(y_test.tolist())\n",
        "\n",
        "        train_data = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
        "        test_data = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\n",
        "\n",
        "        train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "        test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "\n",
        "        # Training loop\n",
        "        self.model.train()\n",
        "        for batch in train_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        # Evaluation\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                input_ids, attention_mask, labels = batch\n",
        "                input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                total_loss += loss.item()\n",
        "                logits = outputs.logits\n",
        "                predictions = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
        "                correct_predictions += torch.sum(predictions == labels).item()\n",
        "                total_predictions += len(labels)\n",
        "\n",
        "        accuracy = correct_predictions / total_predictions\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "        print(f\"Accuracy: {accuracy}, Loss: {avg_loss}\")\n",
        "\n",
        "class TransformerClassifierModel(Model):\n",
        "    def __init__(self, data, text_column, label_column, N):\n",
        "        super().__init__()\n",
        "        self.num_agents = N\n",
        "        self.schedule = RandomActivation(self)\n",
        "\n",
        "        # Create agents\n",
        "        for i in range(self.num_agents):\n",
        "            agent = TransformerClassifierAgent(i, data, text_column, label_column)\n",
        "            self.schedule.add(agent)\n",
        "\n",
        "    def step(self):\n",
        "        self.schedule.step()\n",
        "\n",
        "# Example usage\n",
        "data = pd.read_csv(\"your_dataset.csv\")  # Load your dataset\n",
        "model = TransformerClassifierModel(data, text_column=\"text\", label_column=\"label\", N=1)\n",
        "model.step()  # Run one step (classification and evaluation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "ZSxe1lgRGjJI",
        "outputId": "69515581-488e-4a9b-89e3-ab1cf44a9bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'your_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9dc3ef2b1ed6>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"your_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerClassifierModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Run one step (classification and evaluation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "———————————————————————————————————————"
      ],
      "metadata": {
        "id": "pwZe8IC6FSQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n"
      ],
      "metadata": {
        "id": "bRW2t_1AACPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = models.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        return self.layernorm2(out1 + ffn_output)\n"
      ],
      "metadata": {
        "id": "kAXsep9T_u-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}